---
title: "QC and Sample Size Estimation"
author: "Witold Wolski"
date: "14/12/2020"
output: pdf_document
vignette: >
  %\VignetteIndexEntry{QC and Sample Size Estimation} 
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


# Loading data

Create configuration for MQ peptide file or use function `create_config_MQ_peptide`

```{r createConfig}
library(prolfqua)
library(tidyverse)


```


```{r LoadDataAndConfigure}
datadir <- file.path(find.package("prolfquaData") , "quantdata")
inputMQfile <-  file.path(datadir, "MAXQuant_ComboCourse_p2691_March_2018_WU183012.zip")
inputAnnotation <- file.path(datadir, "annotation_ComboCourse_p2691_March_2018_WU183012.xlsx")

startdata <- prolfqua::tidyMQ_ProteinGroups(inputMQfile)
head(startdata)
annotation <- readxl::read_xlsx(inputAnnotation)
annotation$experiment = "p2691"
head(annotation)

startdata <- inner_join(annotation, startdata, by= "raw.file")
head(startdata)
```

For the sample size estimation we will use bio-reps from one condition. Also remove all proteins identified only by a single peptide.


```{r}
startdata <- startdata %>% filter(condition  == "Ethanol")
startdata <- startdata %>% filter(nr.peptides > 1)

```

Telling `prolfqua` at which columns to look.

The `hierarchy` describes the structure of the MS data e.g, 
  - protein 
  - peptides
  - modified peptides
  - precursor

In this case we have only protein level measurements.

In addition you need to describe the factors of the analysis, i.e, the column containing the explanatory variables.
Then you need to add the intensity column.

```{r}

atable <- AnalysisTableAnnotation$new()
atable$fileName = "raw.file"
atable$hierarchy[["protein_Id"]] <- c("majority.protein.ids")
atable$hierarchyDepth <- 1
atable$setWorkIntensity("mq.protein.intensity")
anaparam <- AnalysisParameters$new()
config <- AnalysisConfiguration$new(atable, anaparam)


config$table$factors[["condition_"]] = "condition"
config$table$factors[["batch_"]] = "experiment"
config$table$factors[["Run_ID"]] = "Run_ID"
config$table$factorDepth <- 1

adata <- setup_analysis(startdata, config)

```


Create the LFQData class instance, remove zeros from data.

```{r filterdata}
lfqdata <- LFQData$new(adata, config)
lfqdata$remove_small_intensities()
```

You can convert the data into wide format.

```{r}
lfqdata$to_wide()$data[1000:1003,1:3]
```


## Visualization of not normalized data

```{r makeMissingHeatmap}
lfqplotter <- lfqdata$get_Plotter()
lfqplotter$intensity_distribution_density()
```


### Visualization of missing data

```{r}
nah <- lfqplotter$NA_heatmap()
```

```{r printMissingHeatmap, fig.cap="Heatmap, black - missing protein intensities, white - present"}
nah
```



```{r fig.cap="# of proteins with 0,1,...N missing values"}
lfqplotter$missingness_per_condition()
```

```{r fig.cap="Cumulative sum of the # of proteins with 0,1,...N missing values"}
lfqplotter$missingness_per_condition_cumsum()
```

```{r fig.cap="Intensity distribution of proteins depending on # of missing values"}
lfqplotter$missigness_histogram()
```

# Computing standard deviations, mean and CV.


```{r PlotCVDistributions}
stats <- lfqdata$get_Stats()
prolfqua::table_facade( stats$stats_quantiles()$wide, paste0("quantile of ",stats$stat ))
```


```{r fig.cap="Distribution of CV's"}
stats$density_median()

```


```{r fig.cap="Scatter plot of standard deviation vs mean"}
stats$stdv_vs_mean(size = 400) + scale_x_log10() + scale_y_log10()
```


## Normalize protein intensities

We normalize the data by $\log2$ transforming and then z-scaling.

```{r normalizedata}
lt <- lfqdata$get_Transformer()
transformed <- lt$log2_robscale()
transformed$config$table$is_intensity_transformed

```

```{r plotDensities, fig.cap="Normalized intensities."}
pl <- transformed$get_Plotter()
pl$intensity_distribution_density()
```

```{r plotScatterMatrix, fig.cap = "Scatterplot matrix"}
pl$pairs_smooth()
```

```{r createHeatmap}
p <- pl$heatmap()
```

```{r plotheatmap, fig.cap="Heatmap, Rows - proteins, Columns - samples", fig.align=5, fig.height=5}
p
```

There is also a function to create an heatmap based on the correlation among samples.

```{r heatmapCor, fig.cap="Heatmap based on sample correlations, Rows - samples, Columns - samples", fig.align=5, fig.height=5}
hc <- pl$heatmap_cor()
```

```{r plotHeatmapCor}
hc
```


```{r showStandardDeviations}
stats <- transformed$get_Stats()
stats$stat
prolfqua::table_facade(stats$stats_quantiles()$wide, "Standard deviations")

```


```{r sddensity, fig.cap="Density of the standard deviation"}
stats$density_median()
```

```{r experiment, include = FALSE}
chsq <- na.omit(stats$statsdf$sd^2)
plot(density(chsq[chsq < 10]))
x <- seq(0,50, length = 1000)
lines(x*median(chsq) , dchisq(x, df = 4 ), col = 2)
```

Check for heteroskedasticity. After transformation the sd should be independent of the mean intensity.

```{r checkForHeteroskedasticity, fig.cap="Scatter plot of sd vs mean of protein intensity"}
stats$stdv_vs_mean(size = 400) + scale_x_log10() + scale_y_log10()
```


## Estimate sample size


```{r estimateSampleSizes}
sampleSize <- stats$power_t_test_quantiles() %>% filter(condition_ != "All")
prolfqua::table_facade(sampleSize, "Sample sizes. delta - Effect size, N - samplesize")

sampleSize %>%
  ggplot(aes(x = factor(probs) , y = N)) +
  facet_wrap(~delta) +
  geom_bar(stat = "identity")

```

Getting statistics for each protein.

```{r stats, eval = TRUE}
stats$stats()

```


Getting the sample size for each protein.

```{r statsWithN, eval = TRUE, fig.cap = "Histogram of sample sizes per protein for three effect sizes."}

x <- stats$power_t_test()
x <- x %>% filter(condition_ == "Ethanol") %>% arrange(protein_Id)
prolfqua::table_facade(x[1000:1007,], caption = "Sample size for each protein")

x %>% ggplot(aes(x = N)) + geom_histogram() + facet_wrap(~delta) + xlim(0,100)

```





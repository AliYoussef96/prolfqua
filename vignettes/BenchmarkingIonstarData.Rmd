---
title: "Benchmarking normalization, aggregation and models using the Ionstar Dataset"
author: "FGCZ - (Draft)"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
papersize: a4
geometry: margin=.5in
vignette: >
  %\VignetteIndexEntry{Benchmarking normalization, aggregation and models using the Ionstar Dataset} 
  %\VignetteEncoding{UTF-8}
  
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---




Please download and install the `prolfquaData` package from github

```{r setup, include=FALSE}
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
fig.width = 10,
fig.height = 10
)
```


```{r}
rm(list = ls())
library(conflicted)
library(prolfqua)
library(tidyverse)
library(dplyr)
conflict_prefer("filter", "dplyr")

```


We start by loading the IonStar dataset and the annotation from the `prolfquaData` package. The method `add_annotation` adds the annotation to the data.

```{r}
datadir <- file.path(find.package("prolfquaData") , "quantdata")
inputMQfile <-  file.path(datadir,
                          "MAXQuant_IonStar2018_PXD003881.zip")
inputAnnotation <- file.path(datadir, "annotation_Ionstar2018_PXD003881.xlsx")

mqdata <- tidyMQ_Peptides_Config(inputMQfile)
annotation <- readxl::read_xlsx(inputAnnotation)


res <- add_annotation(
  mqdata$data,
  annotation,
  fileName = "raw.file"
)

```


```{r}
mqdata$config$table$factors[["dilution."]] = "sample"
mqdata$config$table$factors[["run_Id"]] = "run_ID"
mqdata$config$table$factorDepth <- 1
mqdata$data <- setup_analysis(res, mqdata$config)

```



```{r}
datafilt <- prolfqua::filter_proteins_by_peptide_count(mqdata$data, mqdata$config)$data
```


## Normalize data using HUMAN proteins only



```{r filterForHumans}

lfqdata <- LFQData$new(datafilt, mqdata$config)
tr <- lfqdata$get_Transformer()

subset_h <- lfqdata$get_copy()
subset_h$data <- subset_h$data %>% filter(grepl("HUMAN", protein_Id))
lfqdataNormalized <- tr$log2_robscale_subset(lfqsubset = subset_h)

```


The figures below show the intensity distribution before and after normalization.

```{r PlotIntensityDistributions}
before <- lfqdata$get_Plotter()
before$intensity_distribution_density()

after <- lfqdataNormalized$get_Plotter()
after$intensity_distribution_density()

```


Create a sample of N proteins to speed up computations of models and contrasts.

```{r}
N <- 200
set.seed(2020)
hk <- mqdata$config$table$hkeysDepth()

if (TRUE) {
protein_Ids <- mqdata$data %>%
  select(all_of(hk)) %>%
  distinct() %>%
  sample_n(size = N)
} else {
protein_Ids <- mqdata$data %>%
  select(all_of(hk)) %>%
  distinct() #%>%
  #sample_n(size = N)
}

lfqNormSubset <- lfqdataNormalized$get_copy()
lfqNormSubset$data <- inner_join(protein_Ids, lfqNormSubset$data)
mqdataSubset <- mqdata
mqdataSubset$data  <- inner_join(protein_Ids, mqdata$data)


```




```{r R6Ionstar, echo =  FALSE}
IonstarData <- R6::R6Class(
  "IonstarData",
  public = list(
    data = NULL,
    config = NULL,
    data_N = NULL,
    config_N = NULL,
    
    initialize = function(data, config, data_N, config_N){
      self$data = data
      self$config = config
      self$data_N = data_N
      self$config_N = config_N
    },
    Pep = function(){
      return(list(data = self$data, config = self$config$clone(deep = TRUE)))
    },
    filtered = function(){
      data <- prolfqua:::filter_proteins_by_peptide_count( self$data ,  self$config )$data
      return(list(data = data, config = self$config$clone(deep = TRUE)))
    },
    normalized = function(){
      return(list(data = self$data_N, config = self$config_N))
    },
    subset_normalized = function(){
      return(list(data = self$data_N, config = self$config_N))
    }
  )
)

ionstar <- IonstarData$new(mqdataSubset$data, mqdataSubset$config, 
                           lfqNormSubset$data, lfqNormSubset$config)

#usethis::use_data(ionstar, overwrite = TRUE)

```


# Infer Protein intensities using Tukeys Median Polish

We will be using the `LFQDataAggregator` class. To estimate protein intensities using Tukey's median polish we need to use normalized data.
The figure below shows the the protein estimates (dashed line) and the peptide intensities.

```{r aggregateMedpolish}
lfqAggMedpol <- LFQDataAggregator$new(lfqNormSubset, "protein")
lfqAggMedpol$medpolish()
xx <- lfqAggMedpol$plot()
xx$plots[[1]]
```



```{r storeProteinAggregates, echo = FALSE}
data_IonstarProtein_subsetNorm <- list(
  data = inner_join(protein_Ids,lfqAggMedpol$lfq_agg$data),
  config = lfqAggMedpol$lfq_agg$config
)

#usethis::use_data(data_IonstarProtein_subsetNorm, overwrite = TRUE)

```

We can also estimate the protein intensities using the top N most abundant peptides. In this case we are using the untransformed protein intensities. The figure below shows the estimated protein intensities.

```{r topNAggregation, echo = TRUE}

lfqAggregator <- LFQDataAggregator$new(LFQData$new(mqdataSubset$data, mqdataSubset$config), "protein_topN")
lfqAggregator$mean_topN()
topN <- lfqAggregator$plot()
topN$plots[[1]]

```

# Fitting a linear model to the protein intensities

To fit the linear models we will be using the protein intensities estimated using the Tukeys median polish.

```{r defineContrasts}
DEBUG <- FALSE

Contrasts <- c(
  "dilution_(9/3)_3" =   "dilution.e - dilution.a",
  "dilution_(9/4.5)_2" =   "dilution.e - dilution.b",
  "dilution_(9/6)_1.5" =   "dilution.e - dilution.c",
  "dilution_(9/7.5)_1.2" =   "dilution.e - dilution.d",
  
  "dilution_(7.5/3)_2.5" =   "dilution.d - dilution.a",
  "dilution_(7.5/4.5)_1.6(6)" =   "dilution.d - dilution.b",
  "dilution_(7.5/6)_1.25" =   "dilution.d - dilution.c",
  
  "dilution_(6/3)_2" =   "dilution.c - dilution.a",
  "dilution_(6/4.5)_1.3(3)" =   "dilution.c - dilution.b",
  
  "dilution_(4.5/3)_1.5" =   "dilution.b - dilution.a"
)


tt <- Reduce(rbind, strsplit(names(Contrasts),split = "_"))
tt <- data.frame(tt)[,2:3]
colnames(tt) <- c("ratio" , "expected fold-change")
tt <- tibble::add_column(tt, contrast =  Contrasts, .before = 1)
prolfqua::table_facade(tt, caption = "All possible Contrasts given 5 E. coli dilutions of the Ionstar Dataset")

```


```{r usedContrasts}
relevantContrasts <- c("dilution_(9/7.5)_1.2",
                       "dilution_(7.5/6)_1.25",
                       "dilution_(6/4.5)_1.3(3)",
                       "dilution_(4.5/3)_1.5" )

tt <- Reduce(rbind, strsplit(relevantContrasts,split = "_"))
tt <- data.frame(tt)[,2:3]
colnames(tt) <- c("ratio" , "expected fold-change")
tt <- tibble::add_column(tt, contrast =  Contrasts[names(Contrasts) %in% relevantContrasts], .before = 1)
prolfqua::table_facade(tt, caption = "Contrasts used for benchmark.")
relevantContrasts <- Contrasts[names(Contrasts) %in% relevantContrasts]

```


```{r buildModelLM}
protLFQ <- lfqAggMedpol$lfq_agg

lmmodel <- "~ dilution."
lmmodel <- paste0(protLFQ$config$table$getWorkIntensity() , lmmodel)

modelFunction <- strategy_lm( lmmodel, model_name = "Model")

mod <- prolfqua::build_model(protLFQ$data, modelFunction)


```

```{r computeContrastsModerated}
contr <- prolfqua::Contrasts$new(mod, relevantContrasts)
contr <- prolfqua::ContrastsModerated$new(contr)
contrdf <- contr$get_contrasts()
cp <- contr$get_Plotter()
cp$volcano()

```

# Benchmarking


```{r benchmark}
ttd <- prolfqua::ionstar_bench_preprocess(contrdf)
medpol_benchmark <- make_benchmark(ttd$data,
                                   model_description = "med. polish and lm. density",
                                   model_name = "prot_med_lm",
                                   FDRvsFDP = list(list(sc = "FDR", desc = FALSE))
)


medpol_benchmark$data()
medpol_benchmark$plot_score_distribution()
medpol_benchmark$plot_ROC()
medpol_benchmark$plot_FDRvsFDP()

```

# Imputation

In order to estimate fold-changes of proteins for which linear models could not be fitted because of an excess of missing measurements, the following procedure is applied: The mean intensity of a peptide over all samples in a condition is computed. For the proteins with no observation in one condition, we imputed the peptide intensities using the mean of the 10% smallest average peptide intensities determined in step one. Then the fold changes between conditions were estimated for each peptide, and the median of the peptide fold change estimates was used to provide a per protein fold change. No p-values were estimated in this case. 

```{r benchmarkImputation, eval=TRUE}
contrsimple <- prolfqua::ContrastsSimpleImpute$new(protLFQ, relevantContrasts)

cs <- contrsimple$get_contrasts()
cs <- cs %>% rename(estimate = .data$estimate)
ttd <- prolfqua::ionstar_bench_preprocess(cs)
medpol_benchmark <- make_benchmark(ttd$data,
                                   model_description = "imputed data",
                                   model_name = "pep_imputed_nonparam",
                                   toscale = NULL,
                                   benchmark = list(
                                     list(sc = "estimate", desc = TRUE),
                                     list(sc = "statistic", desc = TRUE)
                                   ),
                                   FDRvsFDP = NULL)

medpol_benchmark$plot_score_distribution()
medpol_benchmark$plot_ROC()
x <- medpol_benchmark$pAUC_summaries()
x$barp

```

# Compare fold changes for both methods

Plot scatter plots for fold changes obtained using the linear model and missing value imputation.

```{r}
cs <- cs %>% select(contrast, protein_Id, est_imp = estimate   )
contrdf <- contrdf %>% select(contrast, protein_Id, est_lm = estimate )
estimates_compare <- inner_join(contrdf, cs)

estimates_compare %>% ggplot(aes(x = est_lm, y = est_imp)) + geom_point()  + 
  geom_smooth(method = 'lm', formula = y~x)


```
